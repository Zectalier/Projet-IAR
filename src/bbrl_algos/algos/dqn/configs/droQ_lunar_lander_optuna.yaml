
# Caution: use only the 'suggest_type' in case of using optuna
save_best: False
plot_agents: False
collect_stats: False

log_dir: ./tmp
video_dir: ${log_dir}/videos

hydra:
  run:
    dir: ${log_dir}/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}

optuna:
  study:
    _target_: optuna.create_study
    study_name: droQ_lunar_lander
    direction: maximize
    pruner:
      _target_: optuna.pruners.MedianPruner
      n_startup_trials: 5
      n_warmup_steps: 5
      interval_steps: 1
  optimize:
    n_trials: 100
    timeout: 86400
    n_jobs: 1


logger:
  classname: bbrl.utils.logger.WandbLogger
  project: "droQ_lunar_lander"
  group: "test_optuna_optim"
  tags: "test_vec_droQ"
  job_type: test
  log_dir: ${log_dir}
  cache_size: 10000
  every_n_seconds: 10
  verbose: False

gym_env:
  env_name: LunarLander-v2
  render_mode: rgb_array

algorithm:
  architecture:
    hidden_size_1: 
      suggest_type: int
      low: 32
      high: 1024
    hidden_size_2: 
      suggest_type: int
      low: 32
      high: 1024
    dropout:
      suggest_type: float
      low: 0.0
      high: 0.5

  seed:
    train: 454534523
    eval: 453543453
    q: 453435432
    explorer: 45345354
    torch: 772534457

  explorer:
    epsilon_start: 0.7
    epsilon_end: 0.05
    decay: 0.996

  buffer:
    max_size: 20_000
    buffer_size: 1e6
    batch_size: 
      suggest_type: int
      low: 32
      high: 1024
    learning_starts: 2000

  target_critic_update_interval: 50
  max_grad_norm: 1.5

  nb_evals: 10
  n_envs: 5
  n_steps_train: 50

  optim_n_updates: 3
  discount_factor: 
    suggest_type: float
    low: 0.5
    high: 0.999

  n_steps: 300_000
  eval_interval: 1000
  n_updates: 32


optimizer:
  classname: torch.optim.Adam
  lr: 
    suggest_type: loguniform
    low: 1e-5
    high: 1e-2