      save_best: True
      plot_agents: False

      logger:
            classname: bbrl.utils.logger.TFLogger
            log_dir: ./tqc_logs/
            verbose: False
            every_n_seconds: 10

      algorithm:
            seed: 4
            n_envs: 8
            n_steps: 20
            eval_interval: 2000
            buffer_size: 2e5
            batch_size: 64
            learning_starts: 10000
            nb_evals: 10
            tau_target: 0.05
            top_quantiles_to_drop: 42
            max_epochs: 50000
            max_grad_norm: 0.5
            discount_factor: 0.95
            entropy_coef: 2.5e-5
            target_entropy: auto
            architecture:
                  actor_hidden_size: [256, 256]
                  critic_hidden_size: [256, 256]
                  n_nets: 2
                  n_quantiles: 25
      gym_env:
            env_name: LunarLanderContinuous-v2

      actor_optimizer:
            classname: torch.optim.Adam
            lr: 1e-4

      critic_optimizer:
            classname: torch.optim.Adam
            lr: 1e-3

      entropy_optimizer:
            classname: torch.optim.Adam
            lr: 1e-3

      entropy_coef_optimizer:
            classname: torch.optim.Adam
            lr: 1e-3
