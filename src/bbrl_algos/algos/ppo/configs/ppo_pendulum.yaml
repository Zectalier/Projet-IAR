      save_best: True
      plot_agents: True
      collect_stats: False

      logger:
            classname: bbrl.utils.logger.TFLogger
            log_dir: ./ppo_logs/
            verbose: False
            every_n_seconds: 10

      algorithm:
            seed:
                  train: 335
                  eval: 983
                  policy: 123
                  torch: 789

            max_grad_norm: 0.5
            n_envs: 8
            n_steps_train: 100
            n_steps: 300000
            eval_interval: 1000
            nb_evals: 10
            gae: 0.95
            discount_factor: 0.9
            clip_range: 0.2
            clip_range_vf: 0
            entropy_coef: 2e-7
            critic_coef: 0.4
            policy_coef: 1
            opt_epochs: 3
            batch_size: 16
            beta: 0.0
            policy_type: TunableVarianceContinuousActor
            architecture:
                  policy_hidden_size: [64, 64]
                  critic_hidden_size: [64, 64]

      gym_env:
            env_name: Pendulum-v1

      optimizer:
            classname: torch.optim.Adam
            lr: 0.001
