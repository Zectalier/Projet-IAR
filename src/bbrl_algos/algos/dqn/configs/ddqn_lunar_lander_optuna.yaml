# Caution: use only the 'suggest_type' in case of using optuna
save_best: False
plot_agents: False
collect_stats: False

log_dir: ./tmp
video_dir: ${log_dir}/videos

hydra:
  run:
    dir: ${log_dir}/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}

optuna:
  study:
    _target_: optuna.create_study
    study_name: dqn_lunar_lander_200K_steps
    direction: maximize
    pruner:
      _target_: optuna.pruners.MedianPruner
      n_startup_trials: 100
      n_warmup_steps: 5
      interval_steps: 1
  optimize:
    n_trials: 100
    timeout: 600
    n_jobs: 50

logger:
  classname: bbrl.utils.logger.WandbLogger
  project: "dqn_lunar_lander_200K_steps"
  group: "test_optuna_optim"
  tags: "test_dqn_lunar_lander_200K_steps"
  job_type: test
  log_dir: ${log_dir}
  cache_size: 10000
  every_n_seconds: 10
  verbose: False

gym_env:
  env_name: LunarLander-v2
  render_mode: rgb_array

algorithm:
  architecture:
    hidden_sizes: [512, 512]

  seed:
    train: 123
    eval: 456
    q: 789
    explorer: 101112
    torch: 131415

  explorer:
    epsilon_start: 0.7
    epsilon_end: 0.05
    decay: 0.996

  buffer:
    max_size: 20_000
    batch_size: 500
    learning_starts: 2000

  target_critic_update_interval: 50
  max_grad_norm: 1.5

  nb_evals: 10
  n_envs: 5
  n_steps_train: 50

  optim_n_updates:
    suggest_type: int
    low: 1
    high: 10
  discount_factor:
    suggest_type: float
    low: 0.9
    high: 0.999

  n_steps: 200_000
  eval_interval: 1000
  n_updates: 32


optimizer:
  classname: torch.optim.Adam
  lr:
    suggest_type: float
    low: 0.0001
    high: 0.001
